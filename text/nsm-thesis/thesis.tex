\documentclass[]{nsm-thesis}
% options:
% [germanthesis] - Thesis is written in German
% [plainunnumbered] - Don't print numbers on plain pages
% [earlydraft] - Settings for quick draft printouts
% [watermark] - Print current time/date at bottom of each page
% [phdthesis] - switch to PhD thesis style
% [twoside] - double sided
% [cutmargins] - text body fills complete page

% Author name. Separate multiple authors with commas.
\author{Dmitriy Monakhov}
\birthday{28. April 1999}
\birthplace{Moscow}

% Title of your thesis.
\title{Improving Urban Traffic Flow with Drone Supported Vehicular Networks}

\thesistype{Master's Thesis in Distributed Systems Engineering}\thesiscite{Master's Thesis~(Masterarbeit)}

\advisors{Mario Franke}
% List of advisors (without academic titles), separated by commas.

% List of referees (without academic titles), separated by commas.
\referees{Christoph Sommer, Burkhard Hensel}


% Define abbreviations used in the thesis here.
%\acrodef{WSN}{Wireless Sensor Network}
\acrodef{MANET}{Mobile Ad Hoc Network}
\acrodef{VANET}{Vehicular Ad Hoc Network}
\acrodef{OSG}{OpenSceneGraph}
\acrodef{MAC}{Medium access control}
\acrodef{NIC}{Network interface controller}
\acrodef{DSRC}{Dedicated Short-Range Communications}
\acrodef{V2V}{Vehicle-to-vehicle}
\acrodef{V2D}{Vehicle-to-drone}
\acrodef{D2D}{Drone-to-drone}
\acrodef{GUI}{Graphical User Interface}
\acrodef{TraCI}{Traffic Control Interface}
\acrodef{ATR}{Average Transmission Range}
%\acrodef{ROI}{Region of Interest}{short-indefinite={an}, long-plural-form={Regions of Interest}}
%\acrodef{ADAC}{German Automobile Association}{foreign={Allgemeiner Deutscher Automobilclub}}
%\acrodef{CANhashing}[CAN]{Content Addressable Network}{extra={when referring to the distributed hash table}}
%\acrodef{CANproto}[CAN]{Controller Area Network}{extra={when referring to the bus protocol}}

\begin{document}

\pagenumbering{roman}

\maketitle

\cleardoublepage


\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\begin{otherlanguage*}{american}

\TODO{Write abstract}

about 1/2 page:
\begin{enumerate}
    \item Motivation (Why do we care?)
    \item Problem statement (What problem are we trying to solve?)
    \item Approach (How did we go about it)
    \item Results (What's the answer?)
    \item Conclusion (What are the implications of the answer?)
\end{enumerate}

The abstract is a miniature version of the thesis.
It should be treated as an entirely separate document.
Do not assume that a reader who has access to an abstract will also have access to the thesis.
Do not assume that a reader who reads the thesis has read the abstract.

\end{otherlanguage*}


\chapter*{Kurzfassung}
\addcontentsline{toc}{chapter}{Kurzfassung}
\begin{otherlanguage*}{ngerman}

\TODO{Write short version of the Abstract in German?}
Gleicher Text (sinngemäß, nicht wörtlich) in Deutsch

\end{otherlanguage*}
\acresetall

\cleardoublepage
\tableofcontents
\TODO{The table of contents should fit on one page. When in doubt, adjust the \texttt{tocdepth} counter.}

\cleardoublepage
\pagenumbering{arabic}



\chapter{Introduction}
%\chapter{Einleitung}
\label{sec:introduction}

Current technology already enables us to create semi-autonomous vehicles. For now fully-autonomous vehicles are rarely allowed to 
populate the roads, in future it will probably be possible. One perspective option for autonomous driving are cooperative autonomous vehicles: such machines
that can drive on their own and maintain situation-awareness via communicating with other vehicles on the roads.

Since our world is rapidly urbanizing, it will be desirable to enable autonomous vehicles to drive in large cities. And there is a problem here: communication between cars will be difficult in urban areas. In cities, buildings stand close to each other. Buildings are usually built of radio-transparent materials. At the same time, the buildings are quite massive. Thus, it turns out that the propagation of radio signals between low-power car transmitters becomes very difficult if the cars are not on the same street. This leads to communication outages in vehicle-to-vehicles networks operating inside urban areas.

One possible solution to this problem could be drones. Cities of the future will probably be populated by autonomous drones flying in the air above the roofs of buildings. This gives drones the advantage of making it much easier for them to maintain a line of sight between each other and with vehicles on the ground. Consequently, their radio transmissions are less likely to be blocked by buildings. In this way, drones can help vehicles spread signals bypassing buildings standing between the vehicles.

In this paper, I explore whether there is an advantage in connecting a network of drones to a network of cars in terms of assisting with urban vehicular traffic.
Since a real-life experiment will be too expensive and difficult to conduct, I will use software simulation.

\chapter{Fundamentals}
\label{sec:fundamentals}

Before the beginning of the work, I will explain the basic terms, technologies and methods that will be used later. I see the Ad-hoc networks as a good starting point.

\section{Ad hoc networks}

A good definition of ad hoc networks was given by Ram Ramanathan and Jason Redi in IEEE communications Magazine \cite{ramanathan2002brief}: An ad hoc network is a (possibly mobile) collection of communications devices (nodes) that wish to communicate, but have no fixed infrastructure available, and have no pre-determined organization of available links. The authors further make a good point, stating that individual nodes are responsible for dynamically discovering which other nodes they can directly communicate with and the nodes are required to relay packets on behalf of other nodes in order to deliver data across the network.

According to Toor et al \cite{toor2008}, Vehicular ad hoc network (\ac{VANET}) is a special case of a mobile ad hoc network, where communication links are formed between the vehicles.

\section{Broadcast Storm}

A common challenge in implementing mobile ad hoc networks (including \acp{VANET}), according to \textcite{wisitrophan2007} is the broadcast storm. Authors define the broadcast storm as a frequent contention and collisions in transmission among neighboring nodes, when the nodes unconditionally broadcast packets. Authors further argue, that multiple solutions exist to alleviate this problem in usual \ac{MANET} environment, but only few are suitable to resolve the broadcast storm issue in \ac{VANET} context.

In my work the broadcast storm is also an issue that needs to be addressed. In my scenario the broadcast storm would be observed between vehicles and between drones if no suppression technique is present. At first, I will list some of the techniques, explored by \textcite{wisitrophan2007} for vehicular ad hoc networks and choose the one that is suitable for my scenario.

\begin{itemize}

\item \textbf{Weighted p-Persistence Broadcasting} - Each node rebroadcasts a packet with a probability that is directly proportional to the distance to the sending node. Duplicate packets are discarded. \cite[Page~88]{wisitrophan2007}.

\item \textbf{Slotted 1-Persistence Broadcasting} - The delay before a packet is rebroadcast depends on the distance to the sending node. Unique packets are always rebroadcast, duplicate packets are discarded. \cite[Page~88]{wisitrophan2007}.

\item \textbf{Slotted p-Persistence Broadcasting} - The delay before a packet is rebroadcast depends on the distance to the sending node. Unique packets are rebroadcast with a predetermined probability, duplicate packets are discarded. \cite[Page~89]{wisitrophan2007}.

\end{itemize}

\textcite{wisitrophan2007} also discuss Received-Signal-Strength-Based broadcast suppression schemes, but since in my work it is assumed that the vehicles always know their exact location, these techniques are not relevant.

\subsection{Weighted p-Persistence Broadcasting}

In my work I will use the Weighted p-Persistence for both vehicles and drones, because it is the simplest to implement and it shows sufficient performance in my scenario. In this section I will describe Weighted p-Persistence Broadcasting in more detail and explain the choice of some parameters.

According to \textcite{wisitrophan2007}, the rule of Weighted p-Persistence can be described like this: Upon receiving a packet from node \emph{i}, node \emph{j} checks the packet ID and rebroadcasts with probability $p_{ij}$ if it receives the packet for the first time; otherwise, it discards the packet.

The formula for calculating $p_{ij}$ looks like this:

\begin{equation}\label{eq:bs-p}
p_{ij} = \frac{D_{ij}}{R}
\end{equation}

where \emph{R} is the average transmission range and $D_{ij}$ is relative distance between nodes \emph{i} and \emph{j}. Authors further add, that if a node receives duplicate packets from multiple sources within the waiting period \emph{WAIT\textunderscore TIME} before rebroadcasting, this node selects the smallest $p_{ij}$ value as rebroadcasting probability. Authors clarify, that this means that nodes use the relative distance to the nearest broadcaster in order to ensure that nodes who are farther away rebroadcast with higher probability. Additionally, authors propose a method to prevent the messages from dying out: if a node decides not to rebroadcast, it keeps the message for time WAIT\textunderscore TIME + $\delta$, where $\delta$ is is the one-hop transmission and propagation delay. If a node does not receive a packet from somebody else, it rebroadcasts it with probability 1 after WAIT\textunderscore TIME + $\delta$.

In my scenario, I will use different \emph{R} values for vehicles and drones. On one hand, since drones maintain the line-of-sight with each other, the R can be relatively large for them, slightly less than there maximum transmission range. On the other hand, vehicles can only communicate withing the length of the street they are standing on. Therefore, the \emph{R} for vehicles will be roughly equal to the length of a city block (distance between two crossroads in a grid, which is much smaller than maximum possible transmission range of a vehicle). This way vehicles, that are standing near two crossroads will rebroadcast with probability around 1. This will ensure that messages can "turn around" the buildings with higher probability.

\section {Related Work}
\TODO{Related Work: merging \acp{VANET} and DroneNETs}

\section {Simulation Software}

As is was mentioned earlier, conducting a full-scale real-life experiment will be very expensive. Therefore a good idea is to use software to simulate the scenario and evaluate the results. 

There are multiple network simulators available on the market. A survey, conducted by \textcite{pan2008survey} contains a list of most popular tools:
\begin{itemize}
\item OPNET \cite[Page~5]{pan2008survey}
\item Network Simulator 2 \cite[Page~7]{pan2008survey}
\item Network Simulator 3 \cite[Page~8]{pan2008survey}
\item OMNeT++ \cite[Page~10]{pan2008survey}
\end{itemize}

The one most suitable for my purposes is the OMNeT++. It is free for academical usage, but the main reason why I chose it is the fact that Veins \cite{Sommer2019} is based on OMNeT++. Veins will be discussed in the next section.

According to \textcite[Page~2]{Varga2010}, OMNeT++ is a discrete-event simulator. According to the author, discrete-event simulator simulates a system whose state, defined by the state of all entities of the system, changes only at discrete points in time and the change of state is triggers by the occurrence of an event.

\section {Veins}

In order to simulate a hybrid network of drones and vehicles a network simulator is not enough. A combined solution is needed to create a realistic scenario consisting of vehicles, buildings and drones. The software must implement a combination of a network simulator and a traffic simulator. My solution is based on Veins by \textcite{Sommer2019}.

\begin{figure}
  	\centering
	\includegraphics[width=1\textwidth]{figures/High-level Veins.png}
	\caption{High-level architecture of Veins. Veins bridges OMNeT++ with SUMO traffic simulator to enable simulation of \acp{VANET} \cite{Sommer2019}}
	\label{fig:veinshighlevel}
\end{figure}

\subsection{SUMO and TraCI}
As shown on \ref{fig:veinshighlevel}, Veins uses SUMO by \textcite[Page~218]{sumo2018} as a traffic simulator. According to the SUMO developers, SUMO is a microscopic traffic simulator, which means that each vehicle and its dynamics are modeled individually.
This a suitable solution for my scenario, because I indeed need each vehicle to be an independent object with its own known position. \cref{fig:sumogui} shows a screenshot of SUMO \ac{GUI}.

According to \textcite{traci}, \ac{TraCI} is a protocol, used to interlink road traffic and network simulators. The authors explain, that this protocol permits to control the behavior of vehicles during simulation time, therefore the network simulator can influence the driver's behavior. SUMO exposes \ac{TraCI} endpoints \cite{sumotraci} and Veins connects to them, allowing OMNeT++ user code to simulate \acp{VANET} \cite[Pages~217-218]{Sommer2019}. According to \textcite{Sommer2019}, Veins receives positions of vehicles from SUMO, these positions are later used as positions for network nodes, modeling vehicles in OMNeT++ simulation environment.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/SUMO-GUI.png}
	\caption{SUMO \ac{GUI} screenshot, gray rectangles depict obstacles (buildings), the black wide lines are the roads, the yellow triangle is a vehicle.}
	\label{fig:sumogui}
\end{figure}

\subsection {Scenario and Car}
\label{sec:scenarioned}

To further understand my implementation of drones in Veins, it is necessary to consider two files included in Veins: the file Scenario.ned \cite{scenarioned} and the file Car.ned \cite{carned}. Scenario.ned defines the overall structure of the network, contains an array of all nodes and a list of auxiliary modules that control the vehicles or participate in the visualization when working with the GUI. The Car.ned file defines the structure of one of the most important modules - Car module, which is the internal representation of a vehicle. It contains, in particular, information about the network controller simulator and information about the user code of the application. Also, the Car module has a sub-module, which is responsible for synchronizing the movement with SUMO. Based on these two files in the future I will implement my version of the scenario, which will include drones in addition to vehicles, as well as support three-dimensional visualization of the scene. 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Scenario.pdf}
	\caption{Simplified diagram of Scenario \cite{scenarioned} network. Not all modules, parameters and connections are shown.}
	\label{fig:scenarioned}
\end{figure}

\cref{fig:scenarioned} shows a simplified diagram of the network in Veins. It is not a diagram of classes in the usual sense, it shows the relationship of OMNeT++-modules and OMNeT++-networks , as well as some parameters that will be of interest in the rest of the work. 

\subsection{2D Simple Shadowing}

Next in my work I will describe the algorithm that calculates the fading of the radio signal, which takes into account three-dimensional objects. My algorithm is based on the Simple Obstacle Shadowing algorithm \cite{SimpleObstacleShadowing} that is implemented in Veins, and therefore I will briefly describe it here. In Veins' Simple Obstacle Shadowing algorithm each building is defined as a 2D-polygon with arbitrary number of vertices. The radio transmission is modeled as a ray starting from sender's antenna and ending in receiver's antenna. The algorithm determines, how much of the total distance the radio signal traveled through a building. Based on this information the algorithm than calculates the power with which the radio signal reaches the receiver. The signal can penetrate an arbitrary number of buildings. The algorithm also allows the user to set values that determine, how much buildings block the signal via their walls and via their interior. A graphical representation of this model can be seen on \cref{fig:SimpleObstacleShadowing}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/SimpleObstacleShadowing.pdf}
	\caption{Visualization of the Simple Obstacle Shadowing algorithm implemented in Veins. The gray rectangles depict buildings (or any other obstacles), white circles are the points of intersection between radio signal and obstacles' walls.}
	\label{fig:SimpleObstacleShadowing}
\end{figure}

\subsection{OpenSceneGraph}

I would like to emphasize the usage of OpenSceneGraph \cite{osg} as a 3D-rendering tool.  OMNeT++ natively supports OpenSceneGraph \cite{omnetpposg}, therefore \ac{OSG} is the most convenient and easy way to implement a 3D scene in OMNeT++. In this work, I will use 3D visualization for debugging purposes.

Veins provides a C++ class for \ac{OSG}-based road visualization. I will utilize this class along with my own vehicle-, drone- and building- visualizers.

\subsection{IEEE 802.11p}
Veins includes a simple simulation model of IEEE 802.11p for vehicle-to-vehicle communication \cite[Page~216]{Sommer2019}. The following brief description of IEEE 802.11p is based on \textcite{jiang2008ieee}.

IEEE 802.11p is a set of standards dedicated exclusively to vehicle-to-vehicle and infrastructure-to-vehicle communication. It uses 75 MHz of \ac{DSRC} spectrum at 5.9 GHz. The primary goal is to enable public safety applications that can help with road safety and improve traffic flow. Private services are permitted to use these frequencies. The \ac{DSRC} band is free, but licensed spectrum, therefore it is more restricted in terms of usages and technologies in comparison to unlicensed spectrums like Wi-Fi. \ac{DSRC} can be used only for vehicular networks, nobody is allowed to develop another technology, that uses the same radio spectrum. The key feature of IEEE 802.11p is the WAVE mode, that allows a vehicles to communicate immediately upon encounter, without the overhead of scanning for channels and executing handshakes. 

In my work I will use Veins-provided IEEE 802.11p simulation model for both vehicles and drones, working in WAVE mode.

\chapter{Implementation}

Now it is time to develop a network model for a scenario in which vehicles and drones will interact within the same virtual space. My implementation is largely based on the model used in Veins, which was discussed in \cref{sec:scenarioned}. My model basically repeats the structure of the model from Veins, as the basic modules remain the same. However, I have integrated into my model drones, support for the third dimension when calculating sight lines, and special modules for using OSG to render a three-dimensional scene. A schematic view on the communication between drones and vehicles can be seen on \cref{fig:vanetscheme}. \cref{fig:dronescenarioned} shows a simplified UML diagram of classes for the OMNeT++ network in my model, the scheme is analogues to \cref{fig:scenarioned} and is meant to show similarities and differences between my model and Veins' model.

\FIXME{VANET scheme.png - Drone image is not mine!}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/VANET scheme.png}
	\caption{Schematic view on the network. My scenario does not include any infrastructure, the \ac{V2V}, \ac{V2D} and \ac{D2D} communication is implemented using the same IEEE 802.11p model, provided by Veins.}
	\label{fig:vanetscheme}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/DroneScenario.pdf}
	\caption{Simplified diagram of DroneScenario network. In contrast to Veins, the following modules were added to the network: ObstacleShadowingVisualizer, Pathfinder, DroneManager and array of Drones. Some modules replace analogues Veins modules to add new functionality: RoadsOsgVisualizer2, ObstacleControl3d, array of Car3d}
	\label{fig:dronescenarioned}
\end{figure}

\section{Drones}

The first issue with implementing my scenario is that Veins does not support drones. Therefore, implementing drones was on of the first steps in my work. The easiest way to implement drones would be to reuse the existing Veins' code, that was used for vehicles. Therefore, drones will in fact only differ in their mobility, but in other things they will mostly share the code with Veins' vehicles.

\cref{fig:dronened} shows a simplified structure of the Drone.ned module. Like the Car.ned from Veins, Drone.ned uses a special submodule for moving in space. To improve simulation efficiency (i.e., to reduce the number of events), all drone movements are performed once every 1 second as part of the single event processing. The DroneManager.ned module is responsible for managing this event (scheduling and execution), as well as for creating and removing drones. Simply put, the DroneManager module creates a specified number of drones, and then sends a position update signal to each drone at a period of 1 second (configurable). 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Drone.pdf}
	\caption{Simplified diagram of Drone module.}
	\label{fig:dronened}
\end{figure}

\subsection{Drone Mobility}

DroneMobility submodule is based on Veins' LinearMobility with some minor changes. The biggest one: DroneMobility does not update itself. Instead, the DroneManager calls a special method that makes DroneMobility to update its position.

The \cref{fig:dronemanagerflow} shows a simplified algorithm for updating the drone's position. The drones themselves use the methods implemented in Veins to update their position. The Z-coordinate of each drone can be set through a configuration file.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/DroneManager.pdf}
	\caption{Simplified flowchart of DroneManager updating DroneMobility submodules of each Drone.}
	\label{fig:dronemanagerflow}
\end{figure}


\section{BaseApplicationLayer}

To integrate the drones more easily, I decided to create an additional level of abstraction: BaseApplicationLayer (\cref{fig:baseapplicationlayer}), which will be common for drones and cars. This class is responsible for automatically assigning network addresses, for keeping track of statistics common to drones and cars, and, importantly, for decisions about relaying incoming messages. BaseApplicationLayer inherits from DemoBaseApplLayer, that is implemented in Veins.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/BaseApplicationLayer.pdf}
	\caption{Simplified flowchart of DroneManager updating DroneMobility submodules of each Drone.}
	\label{fig:baseapplicationlayer}
\end{figure}

The main reason for creating the BaseApplicationLayer is to unify the way how decision about rebroadcasting is made. BaseApplicationLayer holds a reference to a special object of class RebroadcastDecider, which in fact is a virtual class. This object decides whether to rebroadcast the message or not. How exactly it makes this decision for the vehicle or for the drone is irrelevant. The drone or vehicle only receives a decision from this object. So it is relatively easy to change the algorithm that decides whether to retransmit a message. Also it is easy to enable a specific algorithm for both drones and vehicles in the same manner.

\subsection {Rebroadcast Decider}

As you can see in \cref{fig:baseapplicationlayer}, BaseApplicationLayer is associated with an object of the RebroadcastDecider class, which is also an OMNeT++ module. Objects of this class are responsible for rebroadcasting packets. The point of providing a separate object is that both drones and cars can use different interchangeable broadcast storm suppression algorithms. 

The \cref{fig:rebroadcastdeciderseq} shows the sequence of message exchange between the broadcast medium and network nodes (drone or vehicle). In some places, the activation time of the actor is not shown. This is done to indicate that at these points in the sequence the packet processing time is zero in terms of simulation time. Packets reach the RebroadcastDecider instantaneously as soon as they have been received and decoded. It should also be noted that in case the RebroadcastDecider decides to rebroadcast a packet, this can happen at any point in time and any number of times (depending on the particular implementation of the RebroadcastDecider).

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/RebroadcastDecider.png}
	\caption{Simplified flowchart of DroneManager updating DroneMobility submodules of each Drone.}
	\label{fig:rebroadcastdeciderseq}
\end{figure}

\section{Adding the third dimension}

The next problem was that Veins does not support three-dimensional obstacles, and therefore does not take Z coordinate into account when calculating radio signal decay. In my scenario, this is a significant drawback, since drones tend to fly above buildings, and hence their radio transmissions are not affected by buildings. In that case, one could make the radio transmissions between drones simply ignore the buildings. However, such a strategy would ignore radio signals between drones and cars. Drone-vehicle communication cannot be described by simple rules from 2D space with at least acceptable accuracy. Because of this, I decided to implement three-dimensional buildings and, accordingly, a three-dimensional algorithm for signal shadowing.

\subsection{3D buildings and signal shadowing}

In my work I assume that buildings can be approximated as right prisms, example shown in \cref{fig:rightprism}. 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/RightPrism.pdf}
	\caption{Example of a right prism. The bases are two equal arbitrary polygons, and the walls are rectangles with equal height perpendicular to the bases. The right prism can be easily imagined via "extruding" a random polygon straight upwards.}
	\label{fig:rightprism}
\end{figure}

This way a 3D shadowing algorithm can be extended from Veins' Simple Obstacle Shadowing. Instead of looking for intersections of 2D rays with 2D polygons, I will look for intersections of 3D rays with right prisms. The classes, used to augment the Veins' code are shown on \cref{fig:obstacle3d-classes}.  Basically, my class ObstacleControl3d reuses Veins' ObstacleControl and only overrides some methods in order to spawn Obstacle3d objects instead of Veins' Obstacle objects. Also ObstacleControl3d reads obstacles' height from the same xml file, that Veins uses, but additionally reads the \emph{height} attribute to set Obstacle3d's height. If this attribute is not found, ObstacleControl3d uses its configuration parameter to set the default height for obstacles. The search for intersections is done inside Obstacle3d. This class inherits Vein's Obstacle class, but adds new methods that calculate line-right-prism intersection. The simplified flow chart of Obstacle3d's algorithm can be seen on \cref{fig:obstacle3d-flow}. 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Obstacle3d-classes.pdf}
	\caption{Example of a right prism. The bases are two equal arbitrary polygons, and the walls are rectangles with equal height perpendicular to the bases. The right prism can be easily imagined via "extruding" a random polygon straight upwards.}
	\label{fig:obstacle3d-classes}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Obstacle3d-flow.pdf}
	\caption{Flowchart of line-right-prism intersection algorithm. Flow for only single Obstacle3d is shown. The ObstacleControl3d iterates over all Obstacle3d objects, calls their getIntersections() methods and combines results.}
	\label{fig:obstacle3d-flow}
\end{figure}

\subsection{3D visualization}

Developing with algorithms that work with 3D objects becomes very complicated without a possibility of visual debugging. In order to easily debug the simulation I have decided to implement 3D visualization of the virtual environment, including vehicles, drones, and buildings. OMNeT++ supports OpenSceneGraph as a 3D rendering library, and my solution also uses it. 

The central modules that are responsible for 3D visualization in my project are: 

\begin{itemize}

\item \textbf{NodeOsgVisualizer} - provided with a file path to a 3D model, draws this model on the \ac{OSG} canvas using the parent's position. Also utilizes Vehicle's heading angle. 

\item \textbf{Obstacle3d} - in addition to methods for finding intersections with a prism, also draws a prism on the \ac{OSG} canvas.

\item \textbf{ObstacleShadowingVisualizer} - draws radio transmission as 3D lines on the \ac{OSG} canvas. Also shows intersections with 3D obstacles. 

\end{itemize}

\begin{figure}%
    \centering
    \subfloat[Vehicle]{\label{fig:vehicle-model}\includegraphics[width=0.5\textwidth]{figures/car3d-model.png}}%
    \subfloat[Drone]{\label{fig:drone-model}\includegraphics[width=0.5\textwidth]{figures/drone-model.png}}
    \caption{3D models created for the project. 3D visualizations of buildings are generated at runtime.}%
    \label{fig:3dmodels}%
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/ObstacleShadowingVisualizer.png}
	\caption{Flowchart of line-right-prism intersection algorithm. Flow for only single Obstacle3d is shown. The ObstacleControl3d iterates over all Obstacle3d objects, calls their getIntersections() methods and combines results.}
	\label{fig:ObstacleShadowingVisualizer}
\end{figure}


\section{Protocol}

Finally, I will explain the protocol that is used in communication between vehicles and drones. The protocol is based on IEEE 802.11p, a simulation of which is implemented in Veins. 

In my project, a single broadcast message is defined, which the cars send to the air in case of an unforeseen stop. This message is called CarJammingAnnouncement and it contains the following information:

\begin{itemize}

\item \textbf{Sender Address} - integer field, representing a unique address of a network node. The jammed vehicle sets this field to its address upon initial broadcast.

\item \textbf{Serial} - integer field, monotonically increasing counter locally handled by each vehicle. Together with Sender Address makes sure, that each CarJammingAnnouncement is unique.

\item \textbf{Car Road Id} - SUMO id of a road, on which the vehicle is jammed. Its real-life equivalent can be name of a street.

\item \textbf{Car Position} - OMNeT++ coordinates on which the vehicle is jammed. This field's real-life equivalent can be GPS coordinates.

\item \textbf{Sender Timestamp} - time of broadcast. Used to calculate latency.

\item \textbf{Last Rebroadcaster Position} - OMNeT++ coordinate of last node (drone or vehicle) that rebroadcast this message. While the Car Position is always the position of a jammed vehicle, that originally sent the message, the Last Rebroadcaster Position depends on the context of the rebroadcast.

\end{itemize}

\cref{fig:protocol} shows how the CarJammingAnnouncement is propagated through the network. The protocol is based on the distribution of broadcast messages about the occurrence of a traffic jam. When a message is received, the vehicle checks if its route goes through the road whose identifier is contained in the message. If it does, the vehicle remembers this identifier (makes a list of all roads where a traffic jam occurred) and recreates the route so that it does not get into the traffic jam. After receiving the message, the vehicle sends the message back on the air according to the rules for avoiding broadcast storms. Drones act in the same way, except that they ignore the information about the traffic jam in the message. They only rebroadcast a copy of the message.

\begin{figure}%
	\centering
	\subfloat[Step 1]{\label{fig:protocol1}\includegraphics[clip,width=0.5\columnwidth]{figures/Protocol1.png}}
	\hfill
	\subfloat[Step 2]{\label{fig:protocol2}\includegraphics[clip,width=0.5\columnwidth]{figures/Protocol2.png}}
	\hfill
	\subfloat[Step 3]{\label{fig:protocol3}\includegraphics[clip,width=0.5\columnwidth]{figures/Protocol3.png}}
	\caption{Jamming announcement protocol. On step 1 (\cref{fig:protocol1}) the vehicle detects that its speed is zero and broadcasts CarJammingAnnouncement message. The vehicles, who receive the broadcast (\cref{fig:protocol2}), read the road id from the message and adjust their routes in order not to get into the jam. Finally  (\cref{fig:protocol3}), the vehicles rebroadcast the initial message and the receivers perform the same steps. This way the jam announcement propagates through the network. The drones also receive and rebroadcast the announcements in the same manner.}%
	\label{fig:protocol}%
\end{figure}

\section{Pathfinder}

While working on the project, I encountered the need to generate random routes for cars. The Vehicle code in Veins when receiving a message can send a TraCI message to SUMO, which will force the vehicle to re-route, avoiding roads with traffic jams. However, the problem is that in this case, SUMO will re-align the route by the shortest path from the current position of the car to the point to which it was originally going. This led to the fact that the path, which was originally tens of kilometers long, was drastically shortened to hundreds of meters. This caused artifacts in the simulation results. The solution to the problem was the Pathfinder module, which builds random routes for cars, taking into account congestion and a given minimum route length.

There is only one Pathfinder module in the simulation. It stores information about the road structure, taken from the same file that SUMO takes it from. The Pathfinder has methods for constructing random routes. Any vehicle can call these methods if needed and then send the resulting random route to SUMO via TraCI, which will cause the vehicle to follow it.

\chapter{Evaluation}

Now it is time to describe the setup of the experiment, the input and output parameters, and to describe and discuss the results.

\section{Road Network}

For simulating a high-density urban environment the Manhattan Grid was selected. The road networks is a square grid of streets with crossroads in the grid nodes. The buildings are located between the roads in places called city block. The global schematic view on the simulation environment can be seen on \cref{fig:manhattangrid}. \cref{fig:manhattangridblock} explains some parameters. The grid's parameters are based on the real Manhattan, the \cref{tab:manhattangrid} shows the exact values used in my simulation. A 3D view of the simulation environment can be seen on \cref{fig:manhattangrid3d} and \cref{fig:manhattangrid3dblock}. On this picture building heights can be seen.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/ManhattanGrid.png}
	\caption{Global schematic view on the road network and buildings. Each block is 150 meters long, there are 14 blocks in total (15 junctions), which results in a map being square with \SI{2100}{\meter} long sides.}
	\label{fig:manhattangrid}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/ManhattanGridBlock-commented.png}
	\caption{Building-block parameters. Street length - is a distance between two junctions and also the size of a block. Margin is the distance between buildings and the road. Padding is the distance between buildings in one block.}
	\label{fig:manhattangridblock}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/GlobalView3D.png}
	\caption{Building-block parameters. Street length - is a distance between two junctions and also the size of a block. Margin is the distance between buildings and the road. Padding is the distance between buildings in one block.}
	\label{fig:manhattangrid3d}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/GlobalView3D-Block.png}
	\caption{3D view on the block. Buildings of different heights can be seen.}
	\label{fig:manhattangrid3dblock}
\end{figure}

\begin{table}
    \centering
    \begin{tabular}{rlcl}
        \toprule
        Parameter & Min & Const & Max \\
        \midrule
        	Grid size & - & 15 & - \\
        	Street Length & - & \SI{150}{\meter} & - \\
		Grid Subdivisions & - & 3 & - \\
		Margin & - & \SI{15}{\meter} & - \\
		Padding & - & \SI{5}{\meter} & - \\
		Building Height & \SI{10}{\meter} & - & \SI{50}{\meter} \\
        \bottomrule
    \end{tabular}
    \caption{Manhattan Grid Parameters. Const column means that this value is constant (non-random). Min-Max columns show that this value varies and is uniformly distributed between Minimum and Maximum. Grid size is the number of junctions in the side of road network grid. Grid subdivisions is the number of buildings in the side of a city block. Street length - is a distance between two junctions and also the size of a block. Margin is the distance between buildings and the road. Padding is the distance between buildings in one block. Building height is the distribution of heights of buildings. }
    \label{tab:manhattangrid}
\end{table}


\section {Simulation flow}

The simulation starts with SUMO loading the road network and buildings. Next simulation steps are explained in the following list.

\begin{enumerate}
	\item Drones are spawned by the DroneManager. Number of drones is an input parameter. Drones start with random height, speed and angle. See \cref{tab:simulationparams} for value ranges of height and speed.
	\item Vehicles are spawned by SUMO. Number of vehicles is an input parameter. Each vehicle starts following a random route.
	\item The simulator waits for a couple of seconds, determined by the warm-up period (see \cref{tab:simulationparams}).
	\item After the Vehicle Breakdown start time is reached (see \cref{tab:simulationparams}), some vehicles break down. The probability of a break down is called Accident Probability and is an input parameter.
  	\item The broken vehicles broadcast a single CarJammingAnnouncement each and stay on there place until the end of the simulation. They still participate in rebroadcasting.
	\item Not broken vehicles receive the broadcasts of broken vehicles and try to adjust there routes to avoid the broken vehicles.
	\item If a vehicle drives into a broken vehicle (or any other stationary vehicle) it is considered jammed. This vehicle broadcasts a single CarJammingAnnouncement and stands still until the end of the simulation. Jammed vehicles still participate in rebroadcasting.
\end{enumerate}

Both initially-broken and later-jammed vehicles are treated as vehicles in jam. They both contribute to Time of a vehicle being in jam, Number of Jammed Vehicles and Average Vehicle Speed output values. There broadcasts are treated equally for the Received Announcements Ratio output value. 

\section{Input Parameters}

For parametric studies the following input parameters were selected:

\begin{itemize}

	\item \textbf{Number of vehicles} - the number of vehicles that spawn at the beginning of the simulation. Each vehicle spawns at a random position with random predefined route. See \cref{tab:simulationparams} for exact values of vehicle speed.
	
	\item \textbf{Number of drones} - the number of drones that spawn at the beginning of the simulation. Each drone spawns at a random position with random predefined angle and speed. See \cref{tab:simulationparams} for exact values of drone height and speed.
	
	\item \textbf{Vehicle breakdown probability} - probability with which each vehicle breaks down.

	\item \textbf{Channel busy time ratio} - Average value of each vehicle's and each drone's busy time ratios.
\end{itemize}

\begin{table}
    \centering
    \begin{tabular}{rlcl}
        \toprule
        Parameter & Min & Const & Max \\
        \midrule
		Vehicle speed & - & \SI{13.89}{\meter\per\second} & - \\
		Vehicle Breakdown start time & - & \SI{15}{\second} & - \\
		Vehicle Breakdown end time & - & End of simulation & - \\
		Vehicle position update period & - & \SI{1}{\second} & - \\
		Vehicle \ac{ATR} & - & \SI{150}{\meter} & - \\

        	Drone speed & \SI{10}{\meter\per\second} & - & \SI{30}{\meter\per\second} \\
        	Drone flight height & \SI{250}{\meter} & - & \SI{300}{\meter} \\
		Drone position update period & - & \SI{1}{\second} & - \\
		Drone \ac{ATR} & - & \SI{500}{\meter} & - \\

		Simulation time & - & \SI{600}{\second} & - \\
		Warm-up period & - & \SI{10}{\second} & - \\
		
        \bottomrule
    \end{tabular}
    \caption{Static simulation parameters (shared between simulations). Const column means that this value is constant (non-random). Min-Max columns show that this value varies between Minimum and Maximum. Vehicle- and Drone- \ac{ATR} is the estimated average range of communication needed by weighted p-persistence algorithm.}
    \label{tab:simulationparams}
\end{table}

\section{Output values}

The following data was selected as the output to be analyzed:

\begin{itemize}

	\item \textbf{Average vehicle speed} - average speed of traffic. Each vehicle's average speed is calculate as traveled distance divided by simulation time. The average of these speeds is the output parameter.
	
	\item \textbf{Time of a vehicle being stuck in a jam} - average time of each vehicle being in a jam.
	
	\item \textbf{Channel busy time ratio} - Average value of each vehicle's and each drone's busy time ratios.

	\item \textbf{End-to-end latency of broadcasts} - Average time it takes for a jamming announcement to reach a vehicle. Only successful transmissions are considered.

	\item \textbf{Received announcements ratio} - each vehicle keeps a list of received announcements. The received announcements ratio for a particular vehicle is the number of announcements it received divided by a total number of unique broadcast announcements. The output value is the average of received announcements ratio of all vehicles.

	\item \textbf{Number of jammed vehicles} - number of vehicles which stayed still for at least \SI{10}{\second}. This number includes both broken vehicles (vehicles that were "ordered" to break down) and vehicles that failed to avoid the jams for any reason (e.g. did not receive an announcement or it was already too late to change the route).

	\item \textbf{Number of hops} - average number of rebroadcasts it was needed for a message to be received by a vehicle. Only successful transmissions are considered.

\end{itemize}

\section{Results}

Simulation runs were divided into two groups: Number Of Vehicles Evaluation group and Accident Probability Evaluation group. In the first group the Accident Probability was fixed and the simulations received two variables: Number of Vehicles and Number of Drones. In the second group the Number of Vehicles was fixed, the varying part consisted of Accident Probability and Number Of Drones. \cref{tab:inputrange1} and \cref{tab:inputrange2} show the range of values, used in these two cases respectively.

\begin{table}
    \centering
    \begin{tabular}{rlcl}
        \toprule
        Parameter & Start & Stop & Step \\
        \midrule
		Number of vehicles & 20 & 100 & 25 \\
		Number of drones & 0 & 100 & 25 \\
		Accident probability & 0.3 & - & - \\
        \bottomrule
    \end{tabular}
    \caption{Parametric studies: parameter ranges for Number of Vehicles Evaluation group of simulations}
    \label{tab:inputrange1}
\end{table}

\FIXME {Recheck the Number of Vehicles in \cref{tab:inputrange1}}

\begin{table}
    \centering
    \begin{tabular}{rlcl}
        \toprule
        Parameter & Start & Stop & Step \\
        \midrule
		Number of vehicles & 60 & - & - \\
		Number of drones & 0 & 100 & 25 \\
		Accident probability & 0.2 & 0.6 & 0.2 \\
        \bottomrule
    \end{tabular}
    \caption{Parametric studies: parameter ranges for Accident Probability Evaluation group of simulations}
    \label{tab:inputrange2}
\end{table}

\subsection{Received Announcements Ratio}

I chose this metric as the metric to start with because it shows, how drones contribute to the connectivity of the network (by "connectivity" I mean how well the nodes in the network are connected to each other). Basically, if Received Announcements Ratio is 1, then each message is received by all vehicles in the simulation. If Received Announcements Ratio is 0, then no message is received by any vehicle. Although this metric is not precisely the connectivity of the network, it with no doubt correlates with the connectivity. Therefore this metric can be used to determine, how well are the nodes are interconnected and how well the messages disseminated between vehicles. It does not depend heavily on traffic conditions and route generation as some other metrics like average vehicle speed or number of jammed vehicles, for example.

\cref{fig:Evaluation-NumberOfVehicles-ReceivedAnnouncements-NA} shows how Received Announcements Ratio depends on the Number of Drones and Number of Vehicles. This figure depicts 4 subplots for 4 different Number of Vehicles values. The figure includes points when Number of Drones is 0. This means that the simulation contains only vehicles. The ratio is minimal in this case. The ratio increases almost linearly with increase in number of drones until the number reaches 50 with ratio being between 0.59 and 0.75 (depending on Number of Vehicles). The increase is slowed down after that, reaching around 0.8 in all cases. It is clear that the lines' shape only slightly depend on the number of vehicles.

It can be seen that the difference between subplots is minimal at 0, 75 and 100 drones. The difference is the largest when Number of Drones is at 25 and slightly less at 50. This can be explained in this way: when there is no drones, the vehicles barely communicate with each other because of buildings, no matter how many vehicles there are. When the drones are introduces in small numbers, the messages get a chance to escape the streets and get to another side of buildings. However, the distance between drones is still too large to let them communicate with each other (when number of drones is 25, there is only one drone in a square with \SI{420}{\meter} side). Therefore the ratio strongly depends on the number of vehicles, who can transmit messages along the roads. When the number of drones is 75, there is one drone in a square with \SI{242}{\meter} side. This is enough already for drones to communicate with each other, meaning that the number of vehicles does not contribute as much to the network connectivity.

\TODO{Another interesting feature is that the subplot with Number of Vehicles equal to 20...}

\cref{fig:Evaluation-AccidentProbability-ReceivedAnnouncements-NA} shows how Received Announcements Ratio depends on the Number of Drones and Accident Probability. This figure depicts 3 subplots for 3 different Accident Probability values.

In conclusion, it is clear that the drones improve the network connectivity in an urban environment. When number of drones is maximum, almost all messages are received by almost all vehicles in the simulation.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-NumberOfVehicles-ReceivedAnnouncements-NA.pdf}
	\caption{Received Announcements Ratio with Accident Probability = 0.3. The value is calculated as the number of received by a vehicle unique messages divided by total number of unique messages sent.}
	\label{fig:Evaluation-NumberOfVehicles-ReceivedAnnouncements-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-AccidentProbability-ReceivedAnnouncements-NA.pdf}
	\caption{Received Announcements Ratio with Number of Vehicles = 60. The Received Announcements Ratio is calculated as the number of unique messages received by a single vehicle divided by total number of unique messages sent by all vehicles. The Y-axis is the average value between all vehicles.}
	\label{fig:Evaluation-AccidentProbability-ReceivedAnnouncements-NA}
\end{figure}

\subsection{Average Vehicle Speed}

This metric is not very good to evaluate the network connectivity and drone contribution as the Received Announcements Ratio. In fact, average vehicle speed depends on the network connectivity, no matter how this connectivity was achieved. However, this value can be used to check, how well the protocol can improve the traffic flow.

\cref{fig:Evaluation-NumberOfVehicles-VehicleSpeed-NA} shows how Average Vehicle Speed depends from Number of Vehicles and Number of Drones with fixed Accident Probability. \cref{fig:Evaluation-AccidentProbability-VehicleSpeed-NA} shows how Average Vehicle Speed depends from Accident Probability and Number of Drones with fixed Number of Vehicles. It is clearly seen, that the average speed increases with increase in Number of Drones. However, the increase in average is not linear: it increases quicker when the number of drones is low than when the number of drones reaches 100. It is pretty safe to assume that the average speed is increasing due to drones contributing to the network connectivity. 

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-NumberOfVehicles-VehicleSpeed-NA.pdf}
	\caption{Average Vehicle Speed with Accident Probability = 0.3. Initially-broken vehicles are also considered.}
	\label{fig:Evaluation-NumberOfVehicles-VehicleSpeed-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-AccidentProbability-VehicleSpeed-NA.pdf}
	\caption{Average Vehicle Speed with Number of Vehicles = 60. Initially-broken vehicles are also considered.}
	\label{fig:Evaluation-AccidentProbability-VehicleSpeed-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-NumberOfVehicles-Latency-NA.pdf}
	\caption{Average Latency with Accident Probability = 0.3. Latency is the time between an initial broadcast and it's reception by a vehicle. If a message is rebroadcast, its timestamp is not modified, therefore the latency includes the time spent by message being rebroadcast. The latency is calculated on the receiving side, therefore the same broadcast can result in different latencies, depending on the receiver, number of hops and distance, among other factors. Only successful and unique transmissions are considered, receiver does not calculate and record latency of a message, that is a duplicate of earlier received message.}
	\label{fig:Evaluation-NumberOfVehicles-Latency-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-AccidentProbability-Latency-NA.pdf}
	\caption{Average Latency with Number of Vehicles = 60. Latency is the time between an initial broadcast and it's reception by a vehicle. If a message is rebroadcast, its timestamp is not modified, therefore the latency includes the time spent by message being rebroadcast. The latency is calculated on the receiving side, therefore the same broadcast can result in different latencies, depending on the receiver, number of hops and distance, among other factors. Only successful and unique transmissions are considered, receiver does not calculate and record latency of a message, that is a duplicate of earlier received message.}
	\label{fig:Evaluation-AccidentProbability-Latency-NA}
\end{figure}

\FIXME{Check definition of Busy Time!}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-NumberOfVehicles-ChannelBusyTimeRatio-NA.pdf}
	\caption{Average Channel Busy Time Ratio with Accident Probability = 0.3. Busy time ratio is the time, while the antenna is receiving or broadcasting divided by the simulation time. Both vehicles and drones are considered.}
	\label{fig:Evaluation-NumberOfVehicles-ChannelBusyTimeRatio-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-AccidentProbability-ChannelBusyTimeRatio-NA.pdf}
	\caption{Average Channel Busy Time Ratio with Number of Vehicles = 60. Busy time ratio is the time, while the antenna is receiving or broadcasting divided by the simulation time. Both vehicles and drones are considered.}
	\label{fig:Evaluation-AccidentProbability-ChannelBusyTimeRatio-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-NumberOfVehicles-JammedNumber-NA.pdf}
	\caption{Number of Jammed Vehicles with Accident Probability = 0.3. Both initially-broken and later-jammed vehicles are considered.}
	\label{fig:Evaluation-NumberOfVehicles-JammedNumber-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-AccidentProbability-JammedNumber-NA.pdf}
	\caption{Number of Jammed Vehicles with Number of Vehicles = 60. Both initially-broken and later-jammed vehicles are considered.}
	\label{fig:Evaluation-AccidentProbability-JammedNumber-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-NumberOfVehicles-JamTime-NA.pdf}
	\caption{Average Time in Jam with Accident Probability = 0.3. Jam time is the time between the vehicle stopped moving for any reason and the end of the simulation. Only stops longer than 10 seconds are considered a jam. Both initially-broken and later-jammed vehicles are considered.}
	\label{fig:Evaluation-NumberOfVehicles-JamTime-NA}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{figures/Evaluation-AccidentProbability-JamTime-NA.pdf}
	\caption{Average Time in Jam with Number of Vehicles = 60. Jam time is the time between the vehicle stopped moving for any reason and the end of the simulation. Only stops longer than 10 seconds are considered a jam. Both initially-broken and later-jammed vehicles are considered.}
	\label{fig:Evaluation-AccidentProbability-JamTime-NA}
\end{figure}


\chapter{Conclusion}

\cleardoublepage

\listofabbreviations
\clearpage

\listoffigures
\clearpage

\listoftables
\clearpage

\printbibliography

\end{document}
